# Importation des biblioth√®ques n√©cessaires
import pandas as pd  # Manipulation de donn√©es sous forme de DataFrame
import numpy as np  # Gestion des tableaux et calculs num√©riques
import matplotlib.pyplot as plt  # Visualisation des donn√©es
import seaborn as sns  # Am√©lioration des visualisations avec Matplotlib
from datetime import datetime  # Gestion des dates et heures
from sklearn.model_selection import train_test_split  # S√©paration des donn√©es en ensembles d'entra√Ænement et de test
from sklearn.preprocessing import StandardScaler  # Standardisation des donn√©es
from sklearn.neighbors import KNeighborsClassifier  # Mod√®le K-Nearest Neighbors
from sklearn.svm import SVC  # Support Vector Machine pour la classification
from sklearn.tree import DecisionTreeClassifier  # Arbre de d√©cision pour la classification
from sklearn.linear_model import LinearRegression, LogisticRegression  # R√©gression lin√©aire et logistique
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score  # √âvaluation des mod√®les
import xgboost as xgb  # XGBoost pour classification et r√©gression
import os

def convertir_duree_en_mois(duree_str):
    """Convertit une dur√©e de formation exprim√©e en texte en un nombre moyen de mois."""
    if pd.isna(duree_str):  # V√©rifie si la valeur est NaN (valeur manquante)
        return np.nan  # Retourne NaN si la valeur est manquante
    # Extraction des valeurs num√©riques des dur√©es (ex: "3 mois, 6 mois" ‚Üí [3, 6])
    mois = [int(s.split()[0]) for s in duree_str.split(',') if s.split()[0].isdigit()]
    return np.mean(mois) if mois else np.nan  # Retourne la moyenne des valeurs extraites

def pretraiter_donnees(df):
    """Effectue le pr√©traitement des donn√©es en transformant les dates et les dur√©es en valeurs num√©riques."""
    df_processed = df.copy()  # Copie du DataFrame pour √©viter de modifier l'original
    # Suppression des doublons
    df_processed = df_processed.drop_duplicates()
    # Transformation des dates en nombre de jours √©coul√©s depuis la derni√®re activit√©
    if 'Derni√®re_activit√©' in df.columns:
        df_processed['jours_depuis_derniere_activite'] = df_processed['Derni√®re_activit√©'].apply(
            lambda x: (datetime.now() - pd.to_datetime(x)).days if pd.notna(x) else np.nan
        )

    # Conversion des dur√©es de formation en mois
    if 'Dur√©e_apprentissage_par_comp√©tence' in df.columns:
        df_processed['Dur√©e_apprentissage_par_comp√©tence'] = df_processed['Dur√©e_apprentissage_par_comp√©tence'].apply(
            convertir_duree_en_mois
        )
    
    # S√©lection des caract√©ristiques √† utiliser
    features = ['jours_depuis_derniere_activite', 'Dur√©e_apprentissage_par_comp√©tence']
    if 'Score' in df.columns:  # Ajout du score si disponible
        features.append('Score')
    
    X = df_processed[features].copy()
    
    # Remplacement des valeurs manquantes par la moyenne de chaque colonne
    for col in X.columns:
        X[col] = X[col].fillna(X[col].mean())
    
    return X  # Retourne le DataFrame pr√©trait√©

def categoriser_utilisateurs(df, seuil_actif=7, seuil_moderement_actif=30):
    """Cat√©gorise les utilisateurs selon leur activit√© et leur score."""
    if df.empty:
        return pd.Series(dtype=str)  # Retourne une s√©rie vide si le DataFrame est vide
    
    # Calcul des moyennes globales pour comparer les utilisateurs
    moyenne_duree = df['Dur√©e_apprentissage_par_comp√©tence'].mean()
    moyenne_score = df['Score'].mean()
    
    # Fonction interne pour classer chaque utilisateur
    def determiner_categorie(row):
        jours, duree, score = row['jours_depuis_derniere_activite'], row['Dur√©e_apprentissage_par_comp√©tence'], row['Score']
        if jours < seuil_actif and duree > moyenne_duree and score > moyenne_score:
            return 'Actif'
        elif jours < seuil_moderement_actif:
            return 'Mod√©r√©ment Actif'
        return 'Inactif'
    
    return df.apply(determiner_categorie, axis=1)  # Applique la classification √† chaque ligne

def entrainer_modeles(X_train, y_train):
    """Entra√Æne plusieurs mod√®les de classification et les retourne."""
    # Convertir les √©tiquettes textuelles en valeurs num√©riques pour certains mod√®les
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    
    modeles = {
        'KNN': KNeighborsClassifier(n_neighbors=3),  # Algorithme des k plus proches voisins
        'SVM': SVC(kernel='linear'),  # Support Vector Machine avec un noyau lin√©aire
        'Decision Tree': DecisionTreeClassifier(),  # Arbre de d√©cision
        'Logistic Regression': LogisticRegression(max_iter=1000),  # R√©gression logistique 
        'XGBoost': xgb.XGBClassifier(objective='multi:softmax', num_class=len(set(y_train)))  # XGBoost pour classification
    }
    
    # Entra√Ænement de chaque mod√®le sur les donn√©es d'entra√Ænement
    for nom, modele in modeles.items():
        if nom == 'XGBoost':
            modele.fit(X_train, y_train_encoded)
        else:
            modele.fit(X_train, y_train)
    
    # Pour la r√©gression lin√©aire, on va pr√©dire un score num√©rique (par exemple le score)
    # puis utiliser un seuil pour classer
    return modeles, le  # Retourne les mod√®les entra√Æn√©s et l'encodeur

def evaluer_regression_lineaire(X_train, X_test, y_train, y_test):
    """√âvalue les performances de la r√©gression lin√©aire et affiche les r√©sultats."""
    # Encodage des cat√©gories en valeurs num√©riques
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    y_train_encoded = le.fit_transform(y_train)
    y_test_encoded = le.transform(y_test)
    
    # Mod√®le de r√©gression lin√©aire simple (une seule variable explicative)
    regressor_simple = LinearRegression()
    regressor_simple.fit(X_train[:, 0:1], y_train_encoded)  # On utilise seulement la premi√®re feature
    
    # Mod√®le de r√©gression lin√©aire multiple (toutes les variables explicatives)
    regressor_multiple = LinearRegression()
    regressor_multiple.fit(X_train, y_train_encoded)
    
    # Pr√©dictions
    y_pred_simple = regressor_simple.predict(X_test[:, 0:1])
    y_pred_multiple = regressor_multiple.predict(X_test)
    
    # Arrondir les pr√©dictions pour les transformer en classes
    y_pred_simple_class = np.round(y_pred_simple).astype(int)
    y_pred_multiple_class = np.round(y_pred_multiple).astype(int)
    
    # Corriger les valeurs hors limites
    y_pred_simple_class = np.clip(y_pred_simple_class, 0, len(le.classes_) - 1)
    y_pred_multiple_class = np.clip(y_pred_multiple_class, 0, len(le.classes_) - 1)
    
    # Calcul des m√©triques pour la r√©gression
    mse_simple = mean_squared_error(y_test_encoded, y_pred_simple)
    r2_simple = r2_score(y_test_encoded, y_pred_simple)
    
    mse_multiple = mean_squared_error(y_test_encoded, y_pred_multiple)
    r2_multiple = r2_score(y_test_encoded, y_pred_multiple)
    
    # Calcul de l'accuracy pour la classification
    accuracy_simple = accuracy_score(y_test_encoded, y_pred_simple_class)
    accuracy_multiple = accuracy_score(y_test_encoded, y_pred_multiple_class)
    
    print("\nR√©sultats de la R√©gression Lin√©aire:")
    print(f"R√©gression Simple - MSE: {mse_simple:.4f}, R¬≤: {r2_simple:.4f}, Accuracy: {accuracy_simple:.2%}")
    print(f"R√©gression Multiple - MSE: {mse_multiple:.4f}, R¬≤: {r2_multiple:.4f}, Accuracy: {accuracy_multiple:.2%}")
    
    # Conversion des pr√©dictions num√©riques en √©tiquettes d'origine
    y_pred_simple_labels = le.inverse_transform(y_pred_simple_class)
    y_pred_multiple_labels = le.inverse_transform(y_pred_multiple_class)
    
    # Cr√©ation des matrices de confusion
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    sns.heatmap(confusion_matrix(y_test, y_pred_simple_labels), annot=True, fmt='d', cmap='Blues', ax=axes[0])
    axes[0].set_title('Matrice - R√©gression Lin√©aire Simple')
    axes[0].set_xlabel('Pr√©dictions')
    axes[0].set_ylabel('R√©elles')
    
    sns.heatmap(confusion_matrix(y_test, y_pred_multiple_labels), annot=True, fmt='d', cmap='Blues', ax=axes[1])
    axes[1].set_title('Matrice - R√©gression Lin√©aire Multiple')
    axes[1].set_xlabel('Pr√©dictions')
    axes[1].set_ylabel('R√©elles')
    
    plt.tight_layout()
    plt.show()
    
    # Enregistrement de la figure
    regression_matrix_path = "figures/matrices_regression.png"
    fig.savefig(regression_matrix_path)
    print(f"‚úÖ Matrices de confusion pour r√©gression enregistr√©es sous '{regression_matrix_path}'")
    
    return {
        'R√©gression Lin√©aire Simple': accuracy_simple,
        'R√©gression Lin√©aire Multiple': accuracy_multiple
    }

def evaluer_modeles(modeles, X_test, y_test, label_encoder):
    """
    √âvalue les performances de plusieurs mod√®les de classification sur des donn√©es de test.
    """
    resultats = {}  # Dictionnaire pour stocker les scores d'accuracy de chaque mod√®le
    accuracy_scores = {}  # Dictionnaire pour stocker les scores pour la visualisation

    # Cr√©ation du dossier "figures" s'il n'existe pas pour stocker les images g√©n√©r√©es
    os.makedirs("figures", exist_ok=True)

    # Cr√©ation d'une figure contenant plusieurs sous-graphiques pour afficher les matrices de confusion
    fig, axes = plt.subplots(1, len(modeles), figsize=(20, 5))  

    # Boucle sur chaque mod√®le pour √©valuer ses performances
    for i, (nom, modele) in enumerate(modeles.items()):
        # Pr√©diction des √©tiquettes sur les donn√©es de test
        if nom == 'XGBoost':
            y_pred_encoded = modele.predict(X_test)
            y_pred = label_encoder.inverse_transform(y_pred_encoded.astype(int))
        else:
            y_pred = modele.predict(X_test)
        
        # Calcul de l'exactitude du mod√®le
        accuracy = accuracy_score(y_test, y_pred)
        
        # Stockage des r√©sultats dans les dictionnaires
        resultats[nom] = accuracy
        accuracy_scores[nom] = accuracy
        
        # Affichage du rapport de classification du mod√®le
        print(f'\nMod√®le: {nom}')
        print(classification_report(y_test, y_pred))

        # Affichage de la matrice de confusion sous forme graphique avec seaborn
        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', ax=axes[i])
        axes[i].set_title(f'Matrice - {nom}')  # Titre de la matrice
        axes[i].set_xlabel('Pr√©dictions')  # Nom de l'axe des abscisses
        axes[i].set_ylabel('R√©elles')  # Nom de l'axe des ordonn√©es

    # Ajustement de la disposition des sous-graphiques pour √©viter les chevauchements
    plt.tight_layout()

    # Affichage des matrices de confusion
    plt.show()

    # Enregistrement de la figure contenant les matrices de confusion
    confusion_matrix_path = "figures/matrices_confusion.png"
    fig.savefig(confusion_matrix_path)
    print(f"‚úÖ Matrices de confusion enregistr√©es sous '{confusion_matrix_path}'")

    return resultats  # Retourne les scores des mod√®les

def comparer_tous_les_modeles(resultats_classification, resultats_regression):
    """Compare tous les mod√®les de classification et de r√©gression."""
    # Fusion des r√©sultats
    tous_resultats = {**resultats_classification, **resultats_regression}
    
    # G√©n√©ration du graphique de comparaison des scores des mod√®les
    plt.figure(figsize=(12, 6))
    
    # D√©finition des couleurs pour diff√©rencier les types de mod√®les
    colors = []
    models = list(tous_resultats.keys())
    for model in models:
        if model in ['KNN', 'SVM', 'Decision Tree']:
            colors.append('royalblue')  # M√©thodes classiques
        elif model == 'XGBoost':
            colors.append('orangered')  # XGBoost
        else:
            colors.append('forestgreen')  # R√©gressions
    
    # Cr√©ation du graphique √† barres
    bars = plt.bar(models, list(tous_resultats.values()), color=colors)
    
    # Ajout d'une l√©gende
    import matplotlib.patches as mpatches
    classic = mpatches.Patch(color='royalblue', label='M√©thodes classiques')
    xgb = mpatches.Patch(color='orangered', label='XGBoost')
    reg = mpatches.Patch(color='forestgreen', label='R√©gression')
    plt.legend(handles=[classic, xgb, reg])
    
    plt.title('Comparaison des performances de tous les mod√®les')  # Titre du graphique
    plt.xlabel('Mod√®les')  # Nom de l'axe des abscisses
    plt.ylabel('Pr√©cision (Accuracy)')  # Nom de l'axe des ordonn√©es
    plt.ylim(0, 1)  # D√©finition de l'√©chelle de l'axe des ordonn√©es entre 0 et 1
    plt.xticks(rotation=45)  # Rotation des √©tiquettes sur l'axe des x pour une meilleure lisibilit√©
    
    # Ajout des valeurs sur les barres
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.2%}',
                ha='center', va='bottom', rotation=0)
    
    # Ajout d'une ligne horizontale √† la valeur maximale pour r√©f√©rence
    max_accuracy = max(tous_resultats.values())
    plt.axhline(y=max_accuracy, color='red', linestyle='--', alpha=0.7)
    plt.text(0, max_accuracy + 0.02, f'Max: {max_accuracy:.2%}', color='red')
    
    plt.tight_layout()
    
    # Affichage du graphique de comparaison
    plt.show()

    # Enregistrement du graphique de comparaison des performances
    performance_graph_path = "figures/comparaison_tous_modeles.png"
    plt.savefig(performance_graph_path)
    print(f"‚úÖ Comparaison de tous les mod√®les enregistr√©e sous '{performance_graph_path}'")

def main(data_path):
    """Fonction principale qui charge les donn√©es, effectue le pr√©traitement, entra√Æne et √©value les mod√®les."""
    try:
        # Liste d'encodages √† tester pour charger le fichier CSV
        encodings = ['utf-8', 'latin-1', 'cp1252', 'ISO-8859-1']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(data_path, encoding=encoding, delimiter=';')
                print(f"‚úÖ Fichier charg√© avec succ√®s en utilisant l'encodage {encoding}")
                break
            except UnicodeDecodeError:
                print(f"‚ùå L'encodage {encoding} n'a pas fonctionn√©")
                if encoding == encodings[-1]:
                    raise Exception("Impossible de trouver un encodage compatible")
                continue
        
        # V√©rification que le dataset n'est pas vide
        if df.empty:
            print("‚ö† Le fichier CSV est vide. V√©rifiez votre dataset.")
            return
        
        X = pretraiter_donnees(df)  # Pr√©traitement des donn√©es
        y = categoriser_utilisateurs(X)  # Cat√©gorisation des utilisateurs
        
        # S√©paration des donn√©es en ensemble d'entra√Ænement et de test
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
        
        # Standardisation des donn√©es pour am√©liorer la performance des mod√®les
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entra√Ænement des mod√®les de classification
        modeles, label_encoder = entrainer_modeles(X_train_scaled, y_train)
        resultats_classification = evaluer_modeles(modeles, X_test_scaled, y_test, label_encoder)
        
        # √âvaluation des mod√®les de r√©gression lin√©aire
        resultats_regression = evaluer_regression_lineaire(X_train_scaled, X_test_scaled, y_train, y_test)
        
        # Comparaison de tous les mod√®les
        comparer_tous_les_modeles(resultats_classification, resultats_regression)
        
        print("\nPerformances des mod√®les de classification:")
        for nom, score in resultats_classification.items():
            print(f"{nom}: {score:.2%}")  # Affichage des scores en pourcentage
        
        print("\nPerformances des mod√®les de r√©gression:")
        for nom, score in resultats_regression.items():
            print(f"{nom}: {score:.2%}")  # Affichage des scores en pourcentage
        
        # D√©termination du meilleur mod√®le
        tous_resultats = {**resultats_classification, **resultats_regression}
        meilleur_modele = max(tous_resultats, key=tous_resultats.get)
        meilleur_score = tous_resultats[meilleur_modele]
        
        print(f"\nüèÜ Le meilleur mod√®le est '{meilleur_modele}' avec une pr√©cision de {meilleur_score:.2%}")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution : {e}")

# Ex√©cution du script si lanc√© directement
if __name__ == "__main__":
    main("bigdata_user_dataset_1200.csv")